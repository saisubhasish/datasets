{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd85ed6",
   "metadata": {},
   "source": [
    "**1.\tWhy would you want to use the Data API?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d373608",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n",
    "APIs are needed to bring applications together in order to perform a designed function built around sharing data and executing pre-defined processes. They work as the middle man, allowing developers to build new programmatic interactions between the various applications people and businesses use on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4b580",
   "metadata": {},
   "source": [
    "**2.\tWhat are the benefits of splitting a large dataset into multiple files?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d1c3d",
   "metadata": {},
   "source": [
    "The key benefits of splitting a large dataset into multiple files are :\n",
    "    \n",
    "    1. Multiple Users can Access Data Simultaneously\n",
    "    \n",
    "    2. Provides Better Protection\n",
    "    \n",
    "    3. Allows for Future Planning\n",
    "    \n",
    "    4. Easy to Modify User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f79b75",
   "metadata": {},
   "source": [
    "**3.\tDuring training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfc34d",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n",
    "You can use TensorBoard to visualize profiling data: if the GPU is not fully utilized then your input pipeline is likely to be the bottleneck. -You can fix it by making sure it reads and preprocesses the data in multiple threads in parallel, and ensuring it prefetches a few batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb8ca2",
   "metadata": {},
   "source": [
    "**4.\tCan you save any binary data to a TFRecord file, or only serialized protocol buffers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef123d6",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n",
    "Yes we can store any binary data to TFRecord file. Because the TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d2bf2",
   "metadata": {},
   "source": [
    "**5.\tWhy would you go through the hassle of converting all your data to the Example protobuf format? Why not use your own protobuf definition?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea31233",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n",
    "- Protocol buffers format provides a language-neutral, platform-neutral, extensible mechanism for serializing structured data in a forward-compatible and backward-compatible way. It’s like JSON, except it’s smaller and faster, and it generates native language bindings.\n",
    "\n",
    "- Unlike other formats, nested Protobuf messages cannot be written contiguously into a stream without significant buffering. The post doesn't argue to never use Protobuf, but that the trade-off made by the wire-format itself, as opposed to any existing implementation, is unlikely to work for lightweight message senders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd0789",
   "metadata": {},
   "source": [
    "**6.\tWhen using TFRecords, when would you want to activate compression? Why not do it systematically?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f833e70",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670fe99",
   "metadata": {},
   "source": [
    "**7.\tData can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model, or using TF Transform. Can you list a few pros and cons of each option?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e4fa9",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976d926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
